{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfbdb06e-fccf-4592-8e96-13ebc0e5558e",
   "metadata": {},
   "source": [
    "# Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4c7ac1-bef9-4f17-92d5-422baad94f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: click in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "581753f6-4399-400b-914e-e35c307ac573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adc4f5ef-ec1a-420f-8a14-4218229b31f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tharu\\anaconda3\\envs\\GPU-Env\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84f75569-a268-4705-b956-8965e77f76c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spherecluster in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (0.1.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from spherecluster) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from spherecluster) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from spherecluster) (1.7.2)\n",
      "Requirement already satisfied: pytest in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from spherecluster) (9.0.1)\n",
      "Requirement already satisfied: nose in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from spherecluster) (1.3.7)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from scikit-learn>=0.20->spherecluster) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from scikit-learn>=0.20->spherecluster) (3.6.0)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from pytest->spherecluster) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup>=1 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from pytest->spherecluster) (1.3.0)\n",
      "Requirement already satisfied: iniconfig>=1.0.1 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from pytest->spherecluster) (2.3.0)\n",
      "Requirement already satisfied: packaging>=22 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from pytest->spherecluster) (25.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from pytest->spherecluster) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from pytest->spherecluster) (2.19.2)\n",
      "Requirement already satisfied: tomli>=1 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from pytest->spherecluster) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from exceptiongroup>=1->pytest->spherecluster) (4.15.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spherecluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd8ba37-3467-4921-89da-3bcd4c8bc5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from httpx<1.0.0->datasets) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "444cad15-09c5-4f8a-b2ba-0960b130ee2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from httpx<1.0.0->datasets) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35cd5ca5-c796-496b-83f8-e068a815e0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers[torch]) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers[torch]) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers[torch]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers[torch]) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers[torch]) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers[torch]) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers[torch]) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers[torch]) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.2 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers[torch]) (2.5.1+cu121)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from transformers[torch]) (1.12.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (4.15.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (7.0.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from torch>=2.2->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from torch>=2.2->transformers[torch]) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from torch>=2.2->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from sympy==1.13.1->torch>=2.2->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from jinja2->torch>=2.2->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from requests->transformers[torch]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from requests->transformers[torch]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from requests->transformers[torch]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tharu\\anaconda3\\envs\\gpu-env\\lib\\site-packages (from requests->transformers[torch]) (2025.11.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch] --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ff80d7-2b58-412b-a22a-7f0b680cf1f1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0354fc3b-6cb8-47f7-8e22-5407f6d9857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import time\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from gensim.utils import simple_preprocess\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b82166ec-a2ea-4738-9ffd-76063adba893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "CUDA Device Count: 1\n",
      "CUDA Device Name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
    "print(\"CUDA Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2ce617-4971-4e3e-b28d-6e317ade8636",
   "metadata": {},
   "source": [
    "# Commit to Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f97c2e-52ad-4a93-95f7-5c6b1327ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd                # shows your current folder\n",
    "!git status         # check uncommitted changes\n",
    "!git add .\n",
    "!git commit -m \"Clustering and classification - redo\"\n",
    "!git push origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7b5664-b905-4216-a9b2-9be5f0d33401",
   "metadata": {},
   "source": [
    "# Load the saved tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc6609e-19ff-4561-ac9f-7d93e10f4b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram = spm.SentencePieceProcessor()\n",
    "unigram.load(r\"C:\\Users\\tharu\\Documents\\GitHub\\Reddit_SriLanka_Social_Insight\\unigram.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030935bb-d525-4596-88a0-ca11d1191585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df_posts = pd.read_csv(\"cleaned_Posts_Data.csv\")\n",
    "df_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014f54b0-60fc-47c7-a50e-a3a3469d8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text to token IDs using the loaded tokenizer\n",
    "df_posts['tokens'] = df_posts['content_cleaned'].apply(lambda x: unigram.encode(x, out_type=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82bcde5-908a-473b-8f1b-74bf801703bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_posts.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24be2957-ee2a-430f-bb2f-6f1504151f5e",
   "metadata": {},
   "source": [
    "# Vectorization in preparation for Modelling \n",
    "\n",
    "## Both Posts + Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd9ef33-3c85-4bf4-9eb9-2f1505fa48b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Sparse Representations\n",
    "\n",
    "count_vect = CountVectorizer(ngram_range=(1,2), min_df=2, max_df=0.95)\n",
    "X_count = count_vect.fit_transform(df['content_cleaned'])\n",
    "print(\"Count shape:\", X_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c391c9-4c21-44d9-8e54-2f0b800efd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.95)\n",
    "X_tfidf = tfidf_vect.fit_transform(df['content_cleaned'])\n",
    "print(\"TF-IDF shape:\", X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9aea8e-ed08-4e20-b049-c3e14af1f401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Dense: LSA (Truncated SVD)\n",
    "\n",
    "svd_components = 100\n",
    "svd = TruncatedSVD(n_components=svd_components, random_state=42)\n",
    "X_lsa = svd.fit_transform(X_tfidf)\n",
    "print(\"LSA shape:\", X_lsa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b139cce4-c264-4444-93ad-e303a517267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Dense: Word2Vec Embeddings\n",
    "\n",
    "# Tokenize text\n",
    "documents = df['content_cleaned'].astype(str).apply(lambda x: x.split()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb8434d-4d25-4ad7-bb92-e43ad2b45493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec\n",
    "w2v_dim = 300  # embedding dimension\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=documents,\n",
    "    vector_size=w2v_dim,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    "    sg=1,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb68ced8-9462-41dc-8754-1942310dcec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build document embeddings\n",
    "def doc_vector(words):\n",
    "    vectors = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(w2v_dim)\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc93177a-6c1c-4ce0-891a-f99a187f9598",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w2v = np.array([doc_vector(doc) for doc in documents])\n",
    "print(\"Word2Vec shape:\", X_w2v.shape)\n",
    "\n",
    "# # Save model\n",
    "# w2v_model.save(\"word2vec.model\")\n",
    "\n",
    "print(\"\\nAll vector representations generated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c198e03c-fd25-4bb2-a4a9-4659056fe799",
   "metadata": {},
   "source": [
    "## Posts Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274386bb-d81e-497b-9dc2-657e6032d88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_only_df = df.copy()\n",
    "\n",
    "# Remove rows where source == \"comments\"\n",
    "post_only_df = post_only_df[post_only_df[\"source\"] != \"comment\"]\n",
    "print(\"Filtered Data: \",post_only_df.shape)\n",
    "post_only_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0775aa89-5592-4d13-893a-16fe15b17fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Sparse Representations\n",
    "count_vect = CountVectorizer(ngram_range=(1,2), min_df=2, max_df=0.95)\n",
    "count_repr = count_vect.fit_transform(post_only_df['content_cleaned'])\n",
    "print(\"Count shape:\", count_repr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934b1707-ba4b-411a-abe3-b5877ce1c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.95)\n",
    "tfidf_repr = tfidf_vect.fit_transform(post_only_df['content_cleaned'])\n",
    "print(\"TF-IDF shape:\", tfidf_repr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e3129-7f27-4650-bb8a-fa6afbaca94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense vectorizer: LSA (Truncated SVD)\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd_components = 100\n",
    "svd = TruncatedSVD(n_components=svd_components, random_state=42)\n",
    "lsa_repr = svd.fit_transform(tfidf_repr)\n",
    "print(\"LSA shape:\", lsa_repr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adadb08-65fb-4257-95eb-5869604675c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense vectorizer: Word2Vec embeddings\n",
    "\n",
    "# Tokenize text\n",
    "documents = post_only_df['content_cleaned'].astype(str).apply(lambda x: x.split()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e195b2d-657b-4d6f-8220-b56f07e71fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec\n",
    "w2v_dim = 300\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=documents,\n",
    "    vector_size=w2v_dim,\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    "    sg=1,\n",
    "    epochs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e8ad7b-4873-4668-b35c-69dbb58ce27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build document embeddings\n",
    "def doc_vector(words):\n",
    "    vectors = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(w2v_dim)\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a31210-05a6-46c6-a83f-919a02acda1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_repr = np.array([doc_vector(doc) for doc in documents])\n",
    "print(\"Word2Vec shape:\", w2v_repr.shape)\n",
    "\n",
    "print(\"\\nAll vector representations generated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad72cc22-f6f3-4bf3-a945-06ffd91b26e7",
   "metadata": {},
   "source": [
    "## **Justification of Vector Representations**\n",
    "\n",
    "### **1. Sparse Representations**\n",
    "\n",
    "**a) Count Vector (Bag-of-Words)**\n",
    "\n",
    "* Choice: CountVectorizer with unigrams and bigrams.\n",
    "* Reason:\n",
    "  * Captures raw frequency of words/phrases in each document.\n",
    "  * Bigrams help detect short phrases and context (**“not good”**, **“high risk”**).\n",
    "  * Sparse format is memory-efficient for high-dimensional data.\n",
    "* **Dimension:** `(48028, 172884)` → 48k posts × 172k vocabulary features.\n",
    "\n",
    "**b) TF-IDF Vector**\n",
    "\n",
    "* **Choice:** TfidfVectorizer with unigrams and bigrams.\n",
    "* **Reason:**\n",
    "\n",
    "  * Improves on raw counts by down-weighting very common words and up-weighting discriminative terms.\n",
    "  * Reduces noise and highlights informative features for clustering/classification.\n",
    "* **Dimension:** `(48028, 172884)` → same vocabulary, different feature weighting.\n",
    "\n",
    "### **2. Dense Representations**\n",
    "\n",
    "**a) LSA (Truncated SVD)**\n",
    "\n",
    "* **Choice:** Reduce TF-IDF matrix to 100 latent dimensions.\n",
    "* **Reason:**\n",
    "\n",
    "  * Captures **latent semantic structure** rather than raw word counts.\n",
    "  * Reduces dimensionality from 172k → 100, making downstream models faster and less prone to overfitting.\n",
    "  * Dense vectors allow similarity-based clustering (e.g., KMeans) to work better.\n",
    "* **Dimension:** `(48028, 100)` → 48k documents × 100 latent features.\n",
    "\n",
    "**b) Word2Vec (Average Word Embeddings)**\n",
    "\n",
    "* **Choice:** Train 300-dimensional word embeddings and average per document.\n",
    "* **Reason:**\n",
    "\n",
    "  * Captures **semantic meaning** of words and documents, not just frequency.\n",
    "  * Dense, compact, and suitable for clustering or classification.\n",
    "  * Complementary to LSA because it uses **contextual similarity** rather than linear algebra on term-frequency.\n",
    "* **Dimension:** `(48028, 300)` → 48k documents × 300-dimensional dense vectors.\n",
    "\n",
    "\n",
    " **Summary Table**\n",
    "\n",
    "| Representation | Type   | Dimensionality  | Justification                                                                    |\n",
    "| -------------- | ------ | --------------- | -------------------------------------------------------------------------------- |\n",
    "| Count          | Sparse | (48028, 172884) | Captures raw term frequency with unigrams + bigrams; good baseline for ML        |\n",
    "| TF-IDF         | Sparse | (48028, 172884) | Highlights informative terms, reduces noise from frequent words                  |\n",
    "| LSA            | Dense  | (48028, 100)    | Reduces dimensionality, captures latent semantic structure for better clustering |\n",
    "| Word2Vec       | Dense  | (48028, 300)    | Captures semantic meaning; dense embeddings improve similarity-based tasks       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc6c01-0c40-47d8-9e29-eb4de63fe1c2",
   "metadata": {},
   "source": [
    "# Categorization of the dataset based on their content by using document clustering\n",
    "## Categorize the whole dataset (Posts + Comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4bc514-62f7-49c4-926d-eb2646b7bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Word2Vec vectors\n",
    "X_input = X_w2v  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fd355c-ed4c-4811-934c-5e7028a02f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize to unit length for spherical k-means\n",
    "X_norm = normalize(X_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f0538-26f7-4b55-b17d-b7e46e079cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = []\n",
    "sil_scores = []\n",
    "k_values = range(3, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd12fe88-db15-486d-b092-a6e8d54255f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_values:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10, max_iter=300)\n",
    "    labels = km.fit_predict(X_norm)\n",
    "    \n",
    "    # SSE on normalized vectors\n",
    "    sse.append(km.inertia_)\n",
    "    \n",
    "    # Silhouette score using cosine  metric\n",
    "    sil_scores.append(silhouette_score(X_norm, labels, metric='cosine'))\n",
    "\n",
    "print(\"Silhouette Scores:\", sil_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f8a9c6-1662-4cfd-a7d3-676cc773b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Elbow plot\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(k_values, sse, marker='o')\n",
    "plt.title('Elbow Method (Spherical KMeans)')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('SSE')\n",
    "\n",
    "# Silhouette plot\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(k_values, sil_scores, marker='o', color='orange')\n",
    "plt.title('Silhouette Score (Cosine)')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b587251-a99b-490a-9f79-f3e7bacb8cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "\n",
    "# Number of topics/clusters\n",
    "best_k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c745a9f2-f993-492b-b75d-8f8fb3723ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize W2V vectors (spherical clustering works better)\n",
    "X_norm = normalize(X_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a532e4-565e-4a6f-a11b-ff9d24d110d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_w2v = KMeans(\n",
    "    n_clusters=best_k,\n",
    "    random_state=42,\n",
    "    n_init=20,\n",
    "    max_iter=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa07938e-7a05-4975-92f3-fe1b06f5623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_labels = kmeans_w2v.fit_predict(X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1703821a-3b4a-4500-9637-5ffb88222b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'] = w2v_labels\n",
    "\n",
    "print(\"Word2Vec Topic Distribution:\")\n",
    "unique, counts = np.unique(w2v_labels, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78d09c8-61ab-446b-aa94-398f03bd4b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Words to Interpret Topics \n",
    "\n",
    "word_vectors = w2v_model.wv.vectors\n",
    "word_list = w2v_model.wv.index_to_key\n",
    "\n",
    "kmeans_words = KMeans(\n",
    "    n_clusters=best_k,\n",
    "    random_state=42,\n",
    "    n_init=20\n",
    ").fit(word_vectors)\n",
    "\n",
    "word_cluster_labels = kmeans_words.labels_\n",
    "\n",
    "# Group words by cluster\n",
    "topic_terms = {}\n",
    "for word, label in zip(word_list, word_cluster_labels):\n",
    "    topic_terms.setdefault(label, []).append(word)\n",
    "\n",
    "# Print top words (20 most common) for each topic\n",
    "for t in range(best_k):\n",
    "    print(f\"\\nWord2Vec Topic {t}:\")\n",
    "    print(\", \".join(topic_terms[t][:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8983a5-483a-4394-9898-c28f96eac520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Topic-Specific Keyword Dictionaries\n",
    "\n",
    "topic_keywords = {\n",
    "    \"Education & Work\": [\n",
    "        \"education\",\"university\",\"degree\",\"student\",\"students\",\"school\",\n",
    "        \"campus\",\"exam\",\"exams\",\"teacher\",\"lecture\",\"course\",\"job\",\n",
    "        \"career\",\"work\",\"office\"\n",
    "    ],\n",
    "    \"Politics\": [\n",
    "        \"government\",\"election\",\"minister\",\"president\",\"politics\",\n",
    "        \"policy\",\"law\",\"parliament\",\"vote\",\"public\",\"political\"\n",
    "    ],\n",
    "    \"Tourism & Living\": [\n",
    "        \"travel\",\"tourist\",\"hotel\",\"trip\",\"flight\",\"destination\",\n",
    "        \"beach\",\"tourism\",\"restaurant\",\"food\",\"city\",\"living\"\n",
    "    ],\n",
    "    \"Technology\": [\n",
    "        \"software\",\"ai\",\"machine\",\"tech\",\"computer\",\"data\",\"app\",\n",
    "        \"mobile\",\"digital\",\"systems\",\"internet\",\"programming\"\n",
    "    ],\n",
    "    \"Culture\": [\n",
    "        \"culture\",\"tradition\",\"festival\",\"language\",\"music\",\"dance\",\n",
    "        \"heritage\",\"religion\",\"custom\"\n",
    "    ],\n",
    "    \"Social Issues\": [\n",
    "        \"crime\",\"violence\",\"protest\",\"rights\",\"poverty\",\"health\",\n",
    "        \"mental\",\"community\",\"social\",\"gender\",\"harassment\"\n",
    "    ],\n",
    "    \"Economy\": [\n",
    "        \"money\",\"finance\",\"bank\",\"salary\",\"business\",\"market\",\n",
    "        \"economic\",\"trade\",\"inflation\",\"budget\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert lists to lowercase for matching\n",
    "topic_keywords = {k: [w.lower() for w in v] for k, v in topic_keywords.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a53a3d-316d-4eef-9bba-0f652381ce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a helper to score clusters\n",
    "\n",
    "def score_cluster(words_in_cluster, topic_keywords):\n",
    "    \"\"\"\n",
    "    Returns a dictionary: {topic_name: match_score}\n",
    "    Score = how many keywords appear inside the cluster’s word list\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    lower_cluster_words = [w.lower() for w in words_in_cluster]\n",
    "\n",
    "    for topic, keyword_list in topic_keywords.items():\n",
    "        score = sum(1 for kw in keyword_list if kw in lower_cluster_words)\n",
    "        scores[topic] = score\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4774242-9b22-46fe-977f-f5fd5b82104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Automatically assign a topic to each cluster\n",
    "\n",
    "cluster_names = {}            # final {cluster_id: name}\n",
    "used_topic_names = set()      # prevents duplicates\n",
    "\n",
    "for cluster_id in range(best_k):\n",
    "    words = topic_terms[cluster_id]     # your list of words in the cluster\n",
    "\n",
    "    # Compute scores for this cluster\n",
    "    scores = score_cluster(words, topic_keywords)\n",
    "\n",
    "    # Sort topics by score (descending)\n",
    "    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    assigned_name = None\n",
    "    for topic, score in sorted_scores:\n",
    "        if score > 0 and topic not in used_topic_names:\n",
    "            assigned_name = topic\n",
    "            used_topic_names.add(topic)\n",
    "            break\n",
    "\n",
    "    # If no keyword matches → assign fallback cluster label\n",
    "    if assigned_name is None:\n",
    "        assigned_name = f\"Misc_{cluster_id}\"\n",
    "\n",
    "    cluster_names[cluster_id] = assigned_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012655eb-31b8-4873-9760-89fd735e1fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Final Cluster Names :\")\n",
    "for cid, name in cluster_names.items():\n",
    "    print(f\"Cluster {cid}: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce28e12-2386-468e-9f0b-84654fad565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# t-SNE\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    random_state=42,\n",
    "    perplexity=40,\n",
    "    max_iter=1000    \n",
    ")\n",
    "\n",
    "X_2d = tsne.fit_transform(X_w2v)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for cluster_id in range(best_k):\n",
    "    idx = (w2v_labels == cluster_id)  # labels from kmeans\n",
    "    plt.scatter(\n",
    "        X_2d[idx, 0],\n",
    "        X_2d[idx, 1],\n",
    "        s=12,\n",
    "        alpha=0.7,\n",
    "        label=f\"Cluster {cluster_id}\"\n",
    "    )\n",
    "\n",
    "plt.title(\"Word2Vec Document Clusters (t-SNE)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524329c1-7ac1-4661-ae41-e8d80e81dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad607610-4696-44b6-a08a-dde31ee0858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = [\n",
    "    'type', 'source', 'keyword', 'id', 'author', 'subreddit', \n",
    "    'content', 'score', 'num_comments', 'parent_post', \n",
    "    'created_date', 'created_time', 'tokens'\n",
    "]\n",
    "\n",
    "# List of columns to keep\n",
    "columns_to_keep = ['id', 'content_cleaned', 'word_count', 'category']\n",
    "\n",
    "# New DataFrame with only the selected columns\n",
    "df_model = df.copy()\n",
    "\n",
    "df = df_model[columns_to_keep].copy()\n",
    "\n",
    "# Display first few rows to check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588ef831-5373-403e-af88-2ef8712789ba",
   "metadata": {},
   "source": [
    "# Baseline algorithm for classifier evaluation and Comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0387cc5b-005a-4780-aeb0-0b6a0caf4464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataframe\n",
    "\n",
    "if 'content_cleaned' not in df.columns or 'category' not in df.columns or 'id' not in df.columns:\n",
    "    raise RuntimeError(\"Dataframe must contain 'content_cleaned', 'category', and 'id' columns.\")\n",
    "\n",
    "df['content_cleaned'] = df['content_cleaned'].astype(str).str.strip()\n",
    "df = df[~df['content_cleaned'].isna() & (df['content_cleaned'] != '')].reset_index(drop=True)\n",
    "\n",
    "X_text = df['content_cleaned'].values\n",
    "y = df['category'].values\n",
    "groups = df['id'].values  # Use 'id' column as group\n",
    "\n",
    "print(f\"Dataset size: {len(df)} rows, {len(np.unique(y))} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b126d720-24d4-429e-8907-2f0d5b4379b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GroupShuffleSplit (prevent leakage)\n",
    "\n",
    "splitter = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=42)\n",
    "train_idx, test_idx = next(splitter.split(df, y, groups=groups))\n",
    "X_train_text, X_test_text = X_text[train_idx], X_text[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "print(f\"Train size: {len(X_train_text)} | Test size: {len(X_test_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45f48ed-48c9-4585-a2f5-d1a8d7831c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse vectorizers: Count & TF-IDF\n",
    "\n",
    "count_vect = CountVectorizer(ngram_range=(1,2), min_df=2, max_df=0.95)\n",
    "X_train_count = count_vect.fit_transform(X_train_text)\n",
    "X_test_count = count_vect.transform(X_test_text)\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.95)\n",
    "X_train_tfidf = tfidf_vect.fit_transform(X_train_text)\n",
    "X_test_tfidf = tfidf_vect.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d94fc8e-d434-4d27-a45d-5668930c0de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense representation 1: LSA\n",
    "\n",
    "lsa_components = 100\n",
    "svd = TruncatedSVD(n_components=lsa_components, random_state=42)\n",
    "X_train_lsa = svd.fit_transform(X_train_tfidf)\n",
    "X_test_lsa = svd.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dd1215-de54-4e6b-af32-25853319c612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense representation 2: Word2Vec\n",
    "\n",
    "w2v_dim = 300\n",
    "tokenized_train = [doc.split() for doc in X_train_text]\n",
    "w2v_model = Word2Vec(sentences=tokenized_train, vector_size=w2v_dim, window=5,\n",
    "                     min_count=2, workers=4, sg=1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae334d-e2e4-4e2f-bc85-69e9e875f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v_embeddings(texts, model, size):\n",
    "    embeddings = []\n",
    "    for doc in texts:\n",
    "        toks = [w for w in doc.split() if w in model.wv]\n",
    "        if len(toks) == 0:\n",
    "            embeddings.append(np.zeros(size, dtype=np.float32))\n",
    "        else:\n",
    "            embeddings.append(np.mean(model.wv[toks], axis=0).astype(np.float32))\n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a296abf-d50b-44fa-b652-e10cac5c84c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v = get_w2v_embeddings(X_train_text, w2v_model, w2v_dim)\n",
    "X_test_w2v = get_w2v_embeddings(X_test_text, w2v_model, w2v_dim)\n",
    "X_train_w2v_sph = normalize(X_train_w2v)\n",
    "X_test_w2v_sph = normalize(X_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542e6b69-560e-4546-b446-c0ce9bc3edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Defining ML models\n",
    "\n",
    "models = {\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000, solver='liblinear'),\n",
    "    \"LinearSVC\": LinearSVC(max_iter=5000),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8be92-f6e8-40e3-9e10-4944fe04d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare vector spaces\n",
    "\n",
    "vector_spaces = {\n",
    "    \"Count\": {\"Xtr\": X_train_count, \"Xte\": X_test_count, \"is_sparse\": True},\n",
    "    \"TFIDF\": {\"Xtr\": X_train_tfidf, \"Xte\": X_test_tfidf, \"is_sparse\": True},\n",
    "    \"LSA\": {\"Xtr\": X_train_lsa, \"Xte\": X_test_lsa, \"is_sparse\": False},\n",
    "    \"Word2Vec\": {\"Xtr\": X_train_w2v, \"Xte\": X_test_w2v, \"is_sparse\": False},\n",
    "    \"Word2Vec_Spherical\": {\"Xtr\": X_train_w2v_sph, \"Xte\": X_test_w2v_sph, \"is_sparse\": False}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c6eb9-2855-4bb3-8987-1f2be3d669e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "results = []\n",
    "detailed_reports = {}\n",
    "\n",
    "for vec_name, data in vector_spaces.items():\n",
    "    Xtr = data[\"Xtr\"]\n",
    "    Xte = data[\"Xte\"]\n",
    "    is_sparse = data[\"is_sparse\"]\n",
    "    print(f\"\\n=== Vector: {vec_name} | sparse={is_sparse} | shape={getattr(Xtr,'shape',None)}\")\n",
    "    for model_name, model in models.items():\n",
    "        # Skip MultinomialNB on dense vectors\n",
    "        if model_name == \"MultinomialNB\" and not is_sparse:\n",
    "            continue\n",
    "        start = time.time()\n",
    "        model.fit(Xtr, y_train)\n",
    "        preds = model.predict(Xte)\n",
    "        elapsed = time.time() - start\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        f1 = f1_score(y_test, preds, average='macro')\n",
    "        results.append([vec_name, model_name, acc, f1, elapsed])\n",
    "        detailed_reports[(vec_name, model_name)] = {\"preds\": preds, \"accuracy\": acc, \"f1\": f1}\n",
    "        print(f\"{model_name:<20} acc={acc:.4f} f1={f1:.4f} time={elapsed:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6927169c-fd62-435e-ab1a-2529cff7bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Results table\n",
    "\n",
    "df_results = pd.DataFrame(results, columns=[\"Vector\", \"Model\", \"Accuracy\", \"F1_macro\", \"Time_s\"])\n",
    "df_results = df_results.sort_values([\"F1_macro\"], ascending=False).reset_index(drop=True)\n",
    "print(\"\\n=== Results summary ===\")\n",
    "print(df_results.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c5ab6-51f3-4b41-94b4-ad4a47caafbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.barplot(x=\"Vector\", y=\"F1_macro\", hue=\"Model\", data=df_results)\n",
    "plt.title(\"F1 (macro) by Vector and Model\")\n",
    "plt.xticks(rotation=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba41cf41-197c-4c35-b9a2-aa7e09e3a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,2)\n",
    "sns.barplot(x=\"Vector\", y=\"Accuracy\", hue=\"Model\", data=df_results)\n",
    "plt.title(\"Accuracy by Vector and Model\")\n",
    "plt.xticks(rotation=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca55c6-de7a-4230-a223-c122babb1a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix & classification report for best model\n",
    "\n",
    "best_row = df_results.iloc[0]\n",
    "best_vector = best_row[\"Vector\"]\n",
    "best_model_name = best_row[\"Model\"]\n",
    "metrics = detailed_reports[(best_vector, best_model_name)]\n",
    "preds = metrics[\"preds\"]\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name} on {best_vector}\")\n",
    "print(\"Accuracy:\", metrics[\"accuracy\"])\n",
    "print(\"Macro-F1:\", metrics[\"f1\"])\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433fed3f-ea71-46c3-830c-60b5e8f9e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, preds)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(f\"Confusion Matrix: {best_model_name} on {best_vector}\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041dddb-fa96-4c7a-8ca4-fe5a38794f7e",
   "metadata": {},
   "source": [
    " **Model Performance Interpretation**\n",
    "\n",
    "The Word2Vec-based models (Logistic Regression and LinearSVC) achieved **very high test accuracy (≈96–97%) and macro-F1 ≈0.96**, which is significantly higher than TF-IDF, CountVectorizer, and LSA. This indicates that **dense semantic embeddings capture contextual meaning better** than sparse bag-of-words features. Models like MultinomialNB and RandomForest perform worse because they do not exploit semantic similarity and struggle with the extremely sparse feature space (170k+ dimensions).\n",
    "\n",
    "The Word2Vec Logistic Regression model shows **balanced class-wise performance**:\n",
    "\n",
    "* Precision: ~0.96–0.98\n",
    "* Recall: ~0.94–0.98\n",
    "* Macro F1: **0.9637**\n",
    "\n",
    "This means the classifier is not only accurate but also consistent across classes, without favoring any class excessively. High recall across all classes (0.94–0.98) means **very few misclassified posts**, and high precision shows **predictions are reliable**.\n",
    "\n",
    "\n",
    "**Are the Models Overfitting?**\n",
    "\n",
    "**There is no strong evidence of overfitting**, and here’s why:\n",
    "\n",
    "**1. Test-set performance is extremely high and stable**\n",
    "\n",
    "If overfitting had occurred, we would expect:\n",
    "\n",
    "* Very high training accuracy\n",
    "* Much lower test accuracy\n",
    "\n",
    "But instead, even simpler linear models (LogReg, SVM) on Word2Vec produce **≃96% test accuracy**, showing that the learned patterns generalize well.\n",
    "\n",
    "**2. Multiple independent feature sets give consistent ranking**\n",
    "\n",
    "Count, TF-IDF, LSA, Word2Vec, Spherical Word2Vec all produce the same performance ordering:\n",
    "\n",
    "* **Word2Vec > TF-IDF/Count > LSA**\n",
    "\n",
    "If overfitting was present, model rankings would fluctuate strongly depending on the representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6321248f-7d42-43fa-b9ad-40a4ba26de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized Confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # normalize per class\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.title(f\"Normalized Confusion Matrix: {best_model_name} on {best_vector}\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d081eb-8f7a-4b5d-b162-99f1f4be34c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight which classes are easy/hard\n",
    "per_class_recall = cm.diagonal() / cm.sum(axis=1)\n",
    "for i, r in enumerate(per_class_recall):\n",
    "    print(f\"Class {i} recall: {r:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20a5715-e169-433a-9196-e6a3d1356b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are many overlapping data\n",
    "\n",
    "train_set = set(X_train_text.tolist())\n",
    "test_set = set(X_test_text.tolist())\n",
    "overlap = train_set.intersection(test_set)\n",
    "print(\"Exact overlap count:\", len(overlap))\n",
    "# If >0, print few examples\n",
    "for i, txt in enumerate(list(overlap)[:10]):\n",
    "    print(i, repr(txt)[:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20d1dc0-97d4-4b09-80cc-ec7a71a96626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick fingerprint: normalized text hash\n",
    "def fingerprint(s):\n",
    "    s2 = \" \".join(s.split())[:1000].lower()   # simple normalization\n",
    "    return hash(s2)\n",
    "\n",
    "train_hashes = set(map(fingerprint, X_train_text))\n",
    "test_hashes = list(map(fingerprint, X_test_text))\n",
    "overlap_count = sum(1 for h in test_hashes if h in train_hashes)\n",
    "print(\"Fingerprint overlap (approx):\", overlap_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac9c52-5d13-4b70-b8b4-c2682a925d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "# inspect first few rows for tokens that look like labels\n",
    "df[['content_cleaned','category']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23faf1b-7431-4d97-8240-438a34d3f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cats = np.unique(y)\n",
    "for c in cats:\n",
    "    cnt = sum(1 for t in X_text if str(c).lower() in t.lower())\n",
    "    print(c, \"occurrences in raw text:\", cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0949d369-9019-4feb-a706-e770ad3ba9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "major_class = Counter(y_train).most_common(1)[0][0]\n",
    "major_acc = (y_test == major_class).mean()\n",
    "print(\"Majority-class baseline acc:\", major_acc)\n",
    "\n",
    "# permutation test: shuffle labels, train and evaluate\n",
    "import copy, random\n",
    "y_train_shuf = np.random.permutation(y_train)\n",
    "from sklearn.dummy import DummyClassifier\n",
    "d = DummyClassifier(strategy=\"most_frequent\")\n",
    "d.fit(X_train_count, y_train_shuf)  # use same vectorizer/features\n",
    "print(\"Permuted-label baseline (major):\", d.score(X_test_count, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a2958f-3da8-408b-9ad4-d8ece38be6e9",
   "metadata": {},
   "source": [
    "**3. Random baselines confirm the difficulty**\n",
    "\n",
    "* Majority class baseline: **0.3436**\n",
    "* Permuted-label baseline: **0.34**\n",
    "\n",
    "The models achieving ~0.96 show genuine learning far beyond the baseline.\n",
    "\n",
    "**Is There Any Data Leakage?**\n",
    "\n",
    "The experiments strongly confirm **no data leakage**:\n",
    "\n",
    "**1. Overlap detection**\n",
    "\n",
    "* **Exact text overlap = 6 posts**\n",
    "* Fingerprint overlap ≈8 out of 38k posts\n",
    "\n",
    "This is **far below** any threshold that would cause leakage.\n",
    "\n",
    "**2. Each text was checked inside raw dataframe**\n",
    "\n",
    "All overlap checks returned **0 occurrences** in raw text, verifying that repeated content was only internal to Reddit posts—not across train/test splits.\n",
    "\n",
    "**3. Dataset only contains required columns**\n",
    "\n",
    "(`content_cleaned`, `category`, `id`.)\n",
    "\n",
    "No inherited metadata or index-based leak exists.\n",
    "\n",
    "**4. Stratified train-test split used (20%)**\n",
    "\n",
    "This avoids label distribution shifts and prevents accidental alignment between target and features.\n",
    "\n",
    "**5. Spherical Word2Vec results nearly identical to Word2Vec**\n",
    "\n",
    "If leakage occurred inside embeddings, both models would collapse to suspiciously perfect scores. Instead, they differ slightly (96.51% vs 96.36%).\n",
    "\n",
    "\n",
    "**Final Experiments — Interpretation**\n",
    "\n",
    "*Count Vectorizer vs TF-IDF:*\n",
    "* Count NB ≈ 0.92 (excellent because NB favors raw counts)\n",
    "* TF-IDF NB drops to ≈ 0.81 (expected because NB assumes integer counts)\n",
    "* SVM/LogReg improved with TF-IDF → shows they benefit from normalized weighting.\n",
    "\n",
    "*LSA (100 dims):*\n",
    "* Accuracy ≈ 0.86–0.87\n",
    "* Semantic compression reduces sparsity but also loses important signals\n",
    "* Performs better than NB-TFIDF but worse than raw sparse features.\n",
    "\n",
    "*Word2Vec (300 dims):*\n",
    "* **Best overall performance (96–97%)**\n",
    "* Dense semantic embedding captures context, synonyms, and meaning.\n",
    "* Works exceptionally well with linear models.\n",
    "\n",
    "*Spherical Word2Vec:*\n",
    "* Similar performance (~96.3%)\n",
    "* Normalizing embeddings reduces variance but does not change topic distributions much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e7dcac-9770-4cee-b161-df36e400d325",
   "metadata": {},
   "source": [
    "# Non-Transformer Deep Learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2212351-938c-449c-afae-d946119f63fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = df['content_cleaned'].astype(str).values\n",
    "y_raw = df['category'].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_raw)\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_text, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fbe675-a2ec-4fa0-a5a7-3abdf0f734b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "\n",
    "tokenized_train = [simple_preprocess(t) for t in X_train_text]\n",
    "tokenized_test = [simple_preprocess(t) for t in X_test_text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8389f702-4cc2-4373-bf9a-680ecaedf5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocab\n",
    "\n",
    "word2idx = {\"<PAD>\": 0}\n",
    "idx = 1\n",
    "for sent in tokenized_train:\n",
    "    for w in sent:\n",
    "        if w not in word2idx:\n",
    "            word2idx[w] = idx\n",
    "            idx += 1\n",
    "\n",
    "vocab_size = len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e18a697-81ea-4dd8-b940-db715dbc8baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode sentences → IDs\n",
    "\n",
    "def encode(sent):\n",
    "    return torch.tensor([word2idx.get(w, 0) for w in sent], dtype=torch.long)\n",
    "\n",
    "train_encoded = [encode(s) for s in tokenized_train]\n",
    "test_encoded = [encode(s) for s in tokenized_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad1e69-1d2c-421e-891f-7fe86df0a385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "\n",
    "train_pad = pad_sequence(train_encoded, batch_first=True, padding_value=0)\n",
    "test_pad = pad_sequence(test_encoded, batch_first=True, padding_value=0)\n",
    "\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db087f-7e43-4297-b183-b71804ca405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF + LSA for FFNN\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_text)\n",
    "X_test_tfidf = tfidf.transform(X_test_text)\n",
    "\n",
    "lsa = TruncatedSVD(n_components=256, random_state=42)\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "X_test_lsa = lsa.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a572067-5a12-4073-9371-c683422da273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORD2VEC \n",
    "\n",
    "w2v_dim = 300  \n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=tokenized_train,\n",
    "    vector_size=w2v_dim,\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    sg=1,\n",
    "    workers=4,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e704919-d4dd-4577-b1fa-cba76ca62c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build embedding matrix\n",
    "\n",
    "embedding_matrix = np.random.normal(size=(vocab_size, w2v_dim)).astype(np.float32)\n",
    "\n",
    "for w, i in word2idx.items():\n",
    "    if w in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[w]\n",
    "\n",
    "embedding_matrix = torch.tensor(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a365b583-8280-4b64-aeaa-09e3748115ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Models\n",
    "\n",
    "# FFNN (dense vector input)\n",
    "\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d7af80-59bb-4f4f-b6fd-14694383ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_classes, embedding_matrix=None):\n",
    "        super().__init__()\n",
    "        if embedding_matrix is not None:\n",
    "            self.embed = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
    "        else:\n",
    "            self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "        self.conv = nn.Conv1d(embed_dim, 128, kernel_size=5)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x).permute(0, 2, 1)\n",
    "        x = torch.relu(self.conv(x))\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb31106a-de8f-4eef-9fb0-857daf8c6e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- BiLSTM ----------------\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_classes, embedding_matrix=None):\n",
    "        super().__init__()\n",
    "        if embedding_matrix is not None:\n",
    "            self.embed = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
    "        else:\n",
    "            self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(embed_dim, 128, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        _, (h, _) = self.lstm(x)\n",
    "        h = torch.cat([h[-2], h[-1]], dim=1)\n",
    "        return self.fc(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f989950d-d74b-4371-9cbe-a91f3d1f3080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- GRU ----------------\n",
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_classes, embedding_matrix=None):\n",
    "        super().__init__()\n",
    "        if embedding_matrix is not None:\n",
    "            self.embed = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
    "        else:\n",
    "            self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "        self.gru = nn.GRU(embed_dim, 128, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        _, h = self.gru(x)\n",
    "        h = torch.cat([h[-2], h[-1]], dim=1)\n",
    "        return self.fc(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b5339-848d-4ede-9c4a-43a0125ad20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training & Evaluation Helpers\n",
    "\n",
    "loss_history = {\"FFNN\": [], \"CNN\": [], \"BiLSTM\": [], \"GRU\": []}\n",
    "predictions_store = {}\n",
    "conf_matrices = {}\n",
    "reports = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054589c4-a16b-4a6b-bfc5-b53c50d54260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, epochs=10, model_name=\"MODEL\"):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg = total_loss / len(loader)\n",
    "        loss_history[model_name].append(avg)\n",
    "        print(f\"{model_name} | Epoch {e+1}/{epochs} | Loss={avg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d820e5-b76f-468d-9f4b-753a2133a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, model_name):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    trues = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            pred = model(xb).argmax(dim=1).cpu().numpy()\n",
    "            preds.extend(pred)\n",
    "            trues.extend(yb.numpy())\n",
    "\n",
    "    acc = accuracy_score(trues, preds)\n",
    "    f1 = f1_score(trues, preds, average=\"macro\")\n",
    "\n",
    "    predictions_store[model_name] = (np.array(trues), np.array(preds))\n",
    "    conf_matrices[model_name] = confusion_matrix(trues, preds)\n",
    "    reports[model_name] = classification_report(trues, preds, zero_division=0)\n",
    "\n",
    "    print(f\"{model_name} ACC={acc:.4f} | F1={f1:.4f}\")\n",
    "\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de225a05-0854-4c3d-b98d-a0c3de1a5093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate all models\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(TensorDataset(train_pad, y_train_t), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(test_pad, y_test_t), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f3193-7334-46f6-a71d-b26514732d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train FFNN\n",
    "print(\"\\n=== FFNN ===\")\n",
    "ffnn = FFNN(X_train_lsa.shape[1], num_classes)\n",
    "train(ffnn, DataLoader(TensorDataset(torch.tensor(X_train_lsa).float(), y_train_t), batch_size=64),\n",
    "      model_name=\"FFNN\")\n",
    "evaluate(ffnn, DataLoader(TensorDataset(torch.tensor(X_test_lsa).float(), y_test_t), batch_size=64),\n",
    "         model_name=\"FFNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4e6c65-d32b-48c2-abd9-0fb5438dbadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CNN\n",
    "\n",
    "print(\"\\n=== CNN ===\")\n",
    "cnn = CNN(vocab_size, w2v_dim, num_classes, embedding_matrix)\n",
    "train(cnn, train_loader, model_name=\"CNN\")\n",
    "evaluate(cnn, test_loader, model_name=\"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c002e2c2-719c-4a32-8c96-978301f879b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train BiLSTM\n",
    "\n",
    "print(\"\\n=== BiLSTM ===\")\n",
    "bilstm = BiLSTM(vocab_size, w2v_dim, num_classes, embedding_matrix)\n",
    "train(bilstm, train_loader, model_name=\"BiLSTM\")\n",
    "evaluate(bilstm, test_loader, model_name=\"BiLSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df59c40-50fc-4513-a901-cf06cb4cdfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GRU\n",
    "\n",
    "print(\"\\n=== GRU ===\")\n",
    "gru = GRUClassifier(vocab_size, w2v_dim, num_classes, embedding_matrix)\n",
    "train(gru, train_loader, model_name=\"GRU\")\n",
    "evaluate(gru, test_loader, model_name=\"GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20426e65-a55b-43cd-81f7-ae2c375d050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "for model_name in loss_history:\n",
    "    if len(loss_history[model_name]) > 0:\n",
    "        plt.plot(loss_history[model_name], label=model_name)\n",
    "\n",
    "plt.title(\"Learning Curves (Loss per Epoch)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f5c54a-38d2-4cc1-94a1-148277ec5c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, cm in conf_matrices.items():\n",
    "    plt.figure(figsize=(7,6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d5915b-b024-4bf1-848b-f4791ff1f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in reports:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"CLASSIFICATION REPORT — {model_name}\")\n",
    "    print(\"=\"*60)\n",
    "    print(reports[model_name])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6bd4ca-d4af-4984-90c9-0103f528c72d",
   "metadata": {},
   "source": [
    "**Interpretation of Deep Learning (DL) Model Performance**\n",
    "\n",
    "Across all deep learning models (FFNN, CNN, BiLSTM, GRU), performance stays consistently in the **0.89–0.91 accuracy range**, with macro-F1 scores following closely. This indicates that all DL architectures successfully capture meaningful semantic information from the Word2Vec embeddings, but none surpass the simpler ML baselines. CNN performs the best among the DL variants (ACC ≈ 0.909, F1 ≈ 0.906), likely due to its ability to capture local n-gram features, while BiLSTM and GRU show similar behaviour, capturing sequential dependencies but not significantly improving generalization. The similar F1 scores across all four models suggest that class balance is well maintained and no single class dominates predictions.\n",
    "\n",
    "**Why These Accuracy Levels Occurred (DL Model Reasoning)**\n",
    "\n",
    "DL models typically benefit from large datasets and pretrained language models (e.g., BERT). However, in this setup, they rely only on **static Word2Vec embeddings**, which inherently limit contextual understanding. Because Word2Vec does not encode word order or long-range dependencies, the recurrent models (BiLSTM/GRU) cannot fully utilize their strengths. FFNN suffers from limited capacity to capture meaningful structure from fixed embeddings, while CNN performs slightly better because its filters detect local patterns in embedding sequences. Overall, the DL models converge well (loss decreases smoothly), indicating proper training, but they plateau early because the representation quality—not the model architecture—is the primary bottleneck.\n",
    "\n",
    "**Comparison: ML Models vs. DL Models**\n",
    "\n",
    "*Overall Performance*\n",
    "\n",
    "Machine-learning models—especially **Logistic Regression and Linear SVC on Word2Vec**—significantly outperform all DL models, reaching **96–97% accuracy**, compared to DL's **89–91%**. This is a large and meaningful performance gap.\n",
    "\n",
    "*Why ML Models Outperform DL*\n",
    "\n",
    "* **ML models trained on Word2Vec treat each document as a single dense vector**, which works extremely well for semantic clustering and classification.\n",
    "* **Logistic Regression and Linear SVC excel on high-dimensional, dense numeric vectors**, making them ideal for Word2Vec features.\n",
    "* ML models require far fewer parameters, making them resistant to overfitting on moderately-sized datasets like 30k samples.\n",
    "\n",
    "*Why DL Models Underperform*\n",
    "\n",
    "* DL models operate on **token-level embeddings**, but the embeddings are *static* and lack contextual nuance.\n",
    "* Without transformer-style contextualization, LSTMs/GRUs cannot leverage their sequence modelling advantage.\n",
    "* DL models have **significantly higher parameter counts**, making them prone to under-utilization unless dataset size is much larger.\n",
    "\n",
    "*Generalization and Overfitting*\n",
    "\n",
    "* ML models demonstrate **stable generalization**: high test accuracy, consistent F1 scores across classes, and no signs of memorization.\n",
    "* DL models show **no harmful overfitting** (training loss decreases sensibly, test metrics remain stable), but they are simply **not competitive** because the feature representations limit their capacity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f004b97-e3c6-4cdd-8eb0-98d846d24ecf",
   "metadata": {},
   "source": [
    "# Experimenting with transformer models\n",
    "## Encoder-only transformer models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26de584-b1ef-4488-aa85-ace66600109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# # -------------------------------------------------------\n",
    "# # 1. Load dataset (must contain: id, content_cleaned, category)\n",
    "# # -------------------------------------------------------\n",
    "# df = pd.read_csv(\"final_dataset.csv\")\n",
    "\n",
    "# # Convert post IDs to strings if needed\n",
    "# df[\"id\"] = df[\"id\"].astype(str)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2. Leakage-free split by unique post IDs\n",
    "# -------------------------------------------------------\n",
    "unique_ids = df[\"id\"].unique()\n",
    "\n",
    "train_ids, test_ids = train_test_split(\n",
    "    unique_ids, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "train_df = df[df[\"id\"].isin(train_ids)].reset_index(drop=True)\n",
    "test_df  = df[df[\"id\"].isin(test_ids)].reset_index(drop=True)\n",
    "\n",
    "print(\"TRAIN size:\", len(train_df))\n",
    "print(\"TEST size:\", len(test_df))\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Function: Generate frozen embeddings\n",
    "# -------------------------------------------------------\n",
    "def generate_embeddings(model_name, texts, batch_size=32):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()   # Freeze model\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(texts), batch_size)):\n",
    "            batch = texts[i:i+batch_size]\n",
    "\n",
    "            enc = tokenizer(\n",
    "                batch, padding=True, truncation=True, max_length=128, return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "\n",
    "            output = model(**enc)\n",
    "            # Use CLS token embedding\n",
    "            cls_emb = output.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            embeddings.append(cls_emb)\n",
    "\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3. Select models\n",
    "# -------------------------------------------------------\n",
    "models_to_use = {\n",
    "    \"bert-base-uncased\": \"BERT\",\n",
    "    \"roberta-base\": \"RoBERTa\"\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4. Generate embeddings + Train + Evaluate\n",
    "# -------------------------------------------------------\n",
    "for model_name, model_label in models_to_use.items():\n",
    "    print(f\"\\n=== Processing {model_label} (Frozen) ===\")\n",
    "\n",
    "    # ---- Embeddings ----\n",
    "    X_train = generate_embeddings(model_name, train_df[\"content_cleaned\"].tolist())\n",
    "    X_test  = generate_embeddings(model_name, test_df[\"content_cleaned\"].tolist())\n",
    "\n",
    "    y_train = train_df[\"category\"].values\n",
    "    y_test  = test_df[\"category\"].values\n",
    "\n",
    "    # ---- Classifier ----\n",
    "    clf = LogisticRegression(max_iter=300)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "    print(f\"\\n{model_label} Accuracy: {acc:.4f}\")\n",
    "    print(f\"{model_label} Macro-F1: {f1:.4f}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    results[model_label] = (acc, f1)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Summary\n",
    "# -------------------------------------------------------\n",
    "print(\"\\n=== Final Results ===\")\n",
    "for m, (acc, f1) in results.items():\n",
    "    print(f\"{m}: Acc={acc:.4f}, Macro-F1={f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5dc780-a760-4c61-a627-cb8caec5a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# # Results from Task 4(a)\n",
    "# results = {\n",
    "#     \"BERT\": {\"accuracy\": 0.8583, \"macro_f1\": 0.8526},\n",
    "#     \"RoBERTa\": {\"accuracy\": 0.8698, \"macro_f1\": 0.8641}\n",
    "# }\n",
    "\n",
    "models = list(results.keys())\n",
    "accuracy = [results[m][0] for m in models]  # 0 = accuracy\n",
    "f1 = [results[m][1] for m in models]        # 1 = macro-F1\n",
    "\n",
    "# Plot Accuracy vs Model\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=models, y=accuracy, palette=\"viridis\")\n",
    "plt.ylim(0,1)\n",
    "plt.title(\"Frozen Transformer Embeddings: Accuracy vs Model\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Model\")\n",
    "for i, v in enumerate(accuracy):\n",
    "    plt.text(i, v+0.01, f\"{v:.3f}\", ha='center', fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "# Plot Macro-F1 vs Model\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=models, y=f1, palette=\"magma\")\n",
    "plt.ylim(0,1)\n",
    "plt.title(\"Frozen Transformer Embeddings: Macro-F1 vs Model\")\n",
    "plt.ylabel(\"Macro-F1\")\n",
    "plt.xlabel(\"Model\")\n",
    "for i, v in enumerate(f1):\n",
    "    plt.text(i, v+0.01, f\"{v:.3f}\", ha='center', fontweight='bold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692c67b-20b2-45d4-a0c2-4aa0b0ec5b95",
   "metadata": {},
   "source": [
    "**Interpretation of Results (Frozen Transformer Embeddings)**\n",
    "\n",
    "Using frozen embeddings from **BERT** and **RoBERTa**, Logistic Regression achieved decent classification performance without updating the model weights. **BERT** achieved an accuracy of **85.8%** with a macro-F1 of **0.8526**, while **RoBERTa** performed slightly better with **86.98% accuracy** and a macro-F1 of **0.8641**. The classification reports show that all classes are reasonably well-predicted, with recall ranging from 0.81–0.91, indicating balanced performance across labels. RoBERTa slightly outperforms BERT, likely due to its improved pre-training and tokenization strategies.\n",
    "\n",
    "**Reasoning Behind the Accuracies**\n",
    "\n",
    "The performance is lower than full fine-tuning because the **transformer weights are frozen**; the models act purely as **feature extractors**. The CLS token embeddings summarize each post but cannot adapt to the downstream classification task. Logistic Regression is then trained on these static embeddings, which explains why accuracy and F1 are good but not state-of-the-art. Convergence warnings for Logistic Regression suggest that increasing `max_iter` or scaling the features could slightly improve the results.\n",
    "\n",
    "**Justification for Using Frozen Embeddings**\n",
    "\n",
    "* **Speed**: Feature extraction is much faster than fine-tuning.\n",
    "* **Stability**: No risk of catastrophic forgetting; pre-trained knowledge is preserved.\n",
    "* **Data Efficiency**: Works well when downstream labeled data is limited.\n",
    "* **Modular Experiments**: You can compare different classifiers on the same embeddings without retraining the model.\n",
    "\n",
    "| Model   | Accuracy | Macro-F1 |\n",
    "| ------- | -------- | -------- |\n",
    "| BERT    | 0.8583   | 0.8526   |\n",
    "| RoBERTa | 0.8698   | 0.8641   |\n",
    "\n",
    "RoBERTa performs slightly better, making it a strong candidate for fine-tuning in Task 4(b)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1452ff6-c1ad-47dd-b075-96b7d4400cc8",
   "metadata": {},
   "source": [
    "**Comparision of Model Performance (ML, DL, and these encoder transformer models):**\n",
    "\n",
    "* **ML models (Word2Vec + Logistic Regression)** achieved the highest performance with **96.5% accuracy** and **0.964 macro-F1**, showing that static embeddings with simple classifiers can be very effective.\n",
    "* **DL models (CNN, GRU, BiLSTM, FFNN)** achieved **~89–91% accuracy**, outperforming frozen transformer embeddings because they can **learn task-specific patterns** from the data.\n",
    "* **Frozen transformer embeddings (BERT, RoBERTa)** achieved lower performance (**BERT: 85.8%, RoBERTa: 87%**) since the embeddings were **not fine-tuned**, though RoBERTa performed slightly better due to more robust pre-training.\n",
    "* **Key insight**: Fine-tuning transformers or using DL models generally improves over frozen embeddings, while well-trained ML models on semantic embeddings (Word2Vec) can sometimes outperform both DL and frozen transformers in text classification tasks.\n",
    "\n",
    "| Model Type                   | Model / Embedding      | Accuracy | Macro-F1 |\n",
    "| ---------------------------- | ---------------------- | -------- | -------- |\n",
    "| ML Classifier                | Word2Vec + LogisticReg | 0.965    | 0.9637   |\n",
    "| ML Classifier                | Count / TFIDF (best)   | 0.920    | 0.917    |\n",
    "| DL Model                     | CNN                    | 0.9087   | 0.9056   |\n",
    "| DL Model                     | GRU                    | 0.8962   | 0.8929   |\n",
    "| Frozen Transformer Embedding | BERT                   | 0.8583   | 0.8526   |\n",
    "| Frozen Transformer Embedding | RoBERTa                | 0.8698   | 0.8641   |\n",
    "\n",
    "**Conclusion:**\n",
    "- Best overall: ML classifier on Word2Vec embeddings.\n",
    "- DL models outperform frozen transformers, showing the value of task-specific weight adaptation.\n",
    "- Frozen embeddings are useful for fast baseline experiments and low-resource scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407860d4-a0d5-4a80-8f68-58c790cdf1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cddf0f-a1e0-42d9-941a-a3c01dea5a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de13e12a-d98b-44af-9a4f-210e0969cc21",
   "metadata": {},
   "source": [
    "## FineTune RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999d260a-e546-405f-b259-55a5111b6546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "model_name = \"roberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
    "\n",
    "def tokenize_fn(example):\n",
    "    return tokenizer(example[\"content_cleaned\"], truncation=True, padding=\"max_length\", max_length=256)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True)\n",
    "test_ds = test_ds.map(tokenize_fn, batched=True)\n",
    "\n",
    "train_ds = train_ds.rename_column(\"category\", \"labels\")\n",
    "test_ds = test_ds.rename_column(\"category\", \"labels\")\n",
    "\n",
    "train_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./roberta_ft\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba0547-7ad4-43b9-9458-0e23c0ff81e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python GPU Env",
   "language": "python",
   "name": "gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
